---
layout: post
title: Crawl Spider with Scrapy 
---

Basic spider has been discussed in previous post, which allows us to simply scrape information on pages specified on start_urls. However, there might be a case where internal links should be followed and certain urls should be filtered. 

This can be achieved with the help of CrawlSpider. Let's take a look at steps to develop it.